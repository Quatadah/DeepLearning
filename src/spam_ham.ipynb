{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF240 - Machine Learning and Deep Learning\n",
    "\n",
    "## TP 2 - Naive Bayes and Evaluation Metrics\n",
    "\n",
    "By Micha√´l Cl√©ment and Aur√©lie Bugeau\n",
    "\n",
    "Credits:  Vincent Lepetit, Varun Kumar, Mohit Deshpande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives \n",
    "The objective of the practice is to classifiy emails from a dataset as spam or non-spam.\n",
    "\n",
    "You will implement the Naive Bayes classifier, and test the model with several validation metrics.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The code needs to import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "#### Presentation and Loading\n",
    "The dataset used here contained 747 spam and 4825 non-spam (i.e. ham) mails. \n",
    "Emails in the corpus have been already pre-processed in the following ways:\n",
    "\n",
    "- Removal of stop words (and, the, of, etc)\n",
    "- Lemmatization (inludes, included, include are now all considered as include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Category, dtype: int64\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Open the dataset and count the number of spam/ham mails\n",
    "mails = pd.read_csv(\"../assets/spamham.csv\")\n",
    "count = mails['Category'].value_counts()\n",
    "print(count)\n",
    "print(mails.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluation sets\n",
    "Split the dataset into training and evaluation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data as train and evaluation sets\n",
    "msk = np.random.rand(len(mails)) < 0.8\n",
    "training_set = mails[msk]\n",
    "testing_set = mails[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Classification\n",
    "The classifier must be able to predict the label based on the text by implementing the following pseudo code:\n",
    "\n",
    "`if (P('ham' | message ) > P( 'spam' | message )) return ‚Äòham‚Äô\n",
    "else return ‚Äòspam‚Äô`\n",
    "\n",
    "where\n",
    "$$ P(ham | message)~=~ {\\rm Probability ~that~ email~ is ~ham~ given~ that~ it~ has~ certain~ features~} $$\n",
    "$$ P(spam | message)~=~ {\\rm Probability ~that~ email~ is ~spam~ given~ that~ it~ has~ certain~ features~} $$\n",
    "\n",
    "The features will be based on the number of occurence of each word in the message.\n",
    "\n",
    "(See the bag-of-words model: https://en.wikipedia.org/wiki/Bag-of-words_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "Apply the Naive Bayes formula in the following code to implement a classifier. You will consider that:\n",
    "$$P(message | spam) = P(word1 | spam) * P(word2 | spam) *...$$\n",
    "\n",
    " \n",
    "_Note:_ if a word in the testing dataset is not present in the training dataset, you may encounter problems as $P(new | ham)$ or $P(new | spam)$ will be 0 making all product equal to 0.\n",
    "To solve this problem, we should take log on both sides. New pseudo code will be\n",
    "\n",
    "`if (log(P('ham' | message )) > log(P('spam' | message))) return ‚Äòham‚Äô\n",
    "else return ‚Äòspam‚Äô`\n",
    "\n",
    "Then \n",
    "$$ log(P(message| spam)) =  log(P(word1 | spam)) + log(P(word2 | spam)) ‚Ä¶$$\n",
    "\n",
    "But the problem is still not solved. If the classifier encounters a new word that is not present in our training data sets then P(new-word | category) will be 0 and log(0) is undefined. To solve this problem, you must use Laplace smoothing:\n",
    "\n",
    "$$P(word1 | spam) = \\frac{{\\rm number~ of ~}word1 {\\rm~belonging~ to ~category~ spam + 1}}{{\\rm  number ~ of ~words~ belonging~ to ~spam ~}+{ \\rm ~number ~of~ distinct ~words~ in ~training ~datasets~}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize a string into words    \n",
    "def tokenize(text):\n",
    "    return re.split(\"\\W+\", text)\n",
    "\n",
    "# Class for detecting spam using Naive Bayes\n",
    "class SpamDetectorNB(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.numberOfmessages = {} \n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.word_index = {}\n",
    "        self.vocab = set()\n",
    "    \n",
    "\n",
    "    # Compute log class priors log(ùëÉ(‚Ñéùëéùëö)) and log(ùëÉ(spùëéùëö))  \n",
    "    # by counting up how many spam/ham messages are in our dataset and dividing by the total number\n",
    "    def log_priors(self, training_set):\n",
    "        p = mails['Category'].value_counts()[0] / len(mails)\n",
    "        self.log_class_priors['spam'] = np.log(p)\n",
    "        self.log_class_priors['ham'] = np.log(1 - p)\n",
    "        \n",
    "     \n",
    "    # Count how many times each word appears in a text. \n",
    "    # Returns a dictionary that contain for each word indicates the number of times it appears in text. \n",
    "    def get_word_counts(self, text):\n",
    "        word_counts = {}\n",
    "        list_of_words = tokenize(text)\n",
    "        for word in list_of_words:\n",
    "            if word.lower() not in word_counts:\n",
    "                word_counts[word.lower()] = 1\n",
    "            else:\n",
    "                word_counts[word.lower()] += 1\n",
    "        # You can use the Python dictionary method get()\n",
    "        return word_counts\n",
    "    \n",
    "    # Create a dictionary (a vocabulary of words)\n",
    "    # and count words frequency for spam and ham separately\n",
    "    def get_word_frequency(self, training_set):\n",
    "        self.word_counts['spam'] = {}\n",
    "        self.word_counts['ham'] = {}\n",
    "        for _, mail in training_set.iterrows():\n",
    "            label = mail['Category']\n",
    "            text = mail['Message']\n",
    "            # Tokenize each message into words\n",
    "            counts = self.get_word_counts(text)\n",
    "            for word, count in counts.items():\n",
    "                if word not in self.vocab:\n",
    "                    self.word_index[word] = len(self.vocab)\n",
    "                    self.vocab.add(word)\n",
    "                if word not in self.word_counts[label]:\n",
    "                    self.word_counts[label][word] = 0.0\n",
    "                self.word_counts[label][word] += count\n",
    "                \n",
    "                \n",
    "    # Compute all necessary features\n",
    "    def train(self, training_set):\n",
    "        self.log_priors(training_set)\n",
    "        self.get_word_frequency(training_set)\n",
    "        \n",
    "        \n",
    "    def predict(self, testing_set):\n",
    "        result = []\n",
    "        for _, mail in testing_set.iterrows():\n",
    "            label = mail['Category']\n",
    "            text = mail['Message']\n",
    "            \n",
    "            # Tokenize each message into words.\n",
    "            counts = self.get_word_counts(text)\n",
    "            \n",
    "            # Initialize ùëôùëúùëî(ùëÉ(spam|message)) and ùëôùëúùëî(ùëÉ(ham|message)) according to log priors\n",
    "            pham = self.log_class_priors['ham']\n",
    "            pspam = self.log_class_priors['spam']\n",
    "            # COMPLETE\n",
    "            spam_count = len(self.word_counts['spam'])\n",
    "            ham_count = len(self.word_counts['ham'])\n",
    "            # For each message, compute ùëôùëúùëî(ùëÉ(ùëöùëíùë†ùë†ùëéùëîùëí|ùë†ùëùùëéùëö)) and ùëôùëúùëî(ùëÉ(ùëöùëíùë†ùë†ùëéùëîùëí|ùë†ùëùùëéùëö)) \n",
    "            for word, _ in counts.items():\n",
    "                if word not in self.vocab: continue         \n",
    "                # For each word compute log(P(w/spam)) and log(P(w/ham)) \n",
    "                pwham = np.log(self.word_counts['ham'].get(word, 1) / ham_count)\n",
    "                pwspam = np.log(self.word_counts['spam'].get(word, 1)/ spam_count)\n",
    "                # Update ùëôùëúùëî(ùëÉ(ùëöùëíùë†ùë†ùëéùëîùëí|ùë†ùëùùëéùëö)) and ùëôùëúùëî(ùëÉ(ùëöùëíùë†ùë†ùëéùëîùëí|ùë†ùëùùëéùëö)) \n",
    "                pham += pwham\n",
    "                pspam += pwspam\n",
    "            # Decide spam or ham\n",
    "            if pham > pspam:\n",
    "                result.append('ham')\n",
    "            else:\n",
    "                result.append('spam')\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the classifier to the spam dataset\n",
    "sd = SpamDetectorNB()\n",
    "sd.train(training_set)\n",
    "result = sd.predict(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Accuracy and confusion matrix\n",
    "Compute the precision, recall, accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8811\n",
      "recall: 1.0000\n",
      "Accuracy : 0.8838\n",
      "Classification error : 0.1162\n",
      "Confusion matrix using SpamDetectorNB: \n",
      " [[978 132]\n",
      " [  0  26]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we assume that ham is positive and spam is negative\n",
    "result_true = testing_set['Category'].values\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(result)):\n",
    "    if result[i] == 'ham' and result_true[i] == 'ham':\n",
    "        TP += 1\n",
    "    elif result[i] == 'spam' and result_true[i] == 'ham':\n",
    "        FP += 1\n",
    "    elif result[i] == 'spam' and result_true[i] == 'spam':\n",
    "        TN += 1\n",
    "    elif result[i] == 'ham' and result_true[i] == 'spam':\n",
    "        TP += 1\n",
    "\n",
    "precision = (TP / (TP + FP))\n",
    "recall = (TP / (TP + FN))\n",
    "accuracy = ((TP + TN) / (TP + TN + FP + FN))\n",
    "print(\"Precision: {0:.4f}\".format(precision))\n",
    "print(\"recall: {0:.4f}\".format(recall))\n",
    "print(\"Accuracy : {0:.4f}\".format(accuracy))\n",
    "print(\"Classification error : {0:.4f}\".format(1 - accuracy))\n",
    "M = np.array([[TP, FP], [FN, TN]])\n",
    "plt.matshow(M, cmap=plt.cm.Blues)\n",
    "print(\"Confusion matrix using SpamDetectorNB: \\n\", M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Naive Bayes with Scikit-learn library\n",
    "The `scikit-learn` library proposes many functions for machine learning.  Study the documentation of the  `MultinomialNB` class and apply it for spam detection.\n",
    "\n",
    "You will need to convert the dataset into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Evaluation with Scikit-learn library\n",
    "\n",
    "The `scikit-learn` library also proposes  functions to evaluate machine learning methods.\n",
    "\n",
    "Apply them to the spam detection problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "# COMPLETE\n",
    "\n",
    "# For visualisation of the confusion matrix\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "sns.heatmap(cmMNb.T, square=True, annot=True, fmt='d', cbar=False) # xticklabels=,yticklabels="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
